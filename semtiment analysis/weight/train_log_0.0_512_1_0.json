["total parameters: 6657634, trainable parameters: 6657634", "\n        dropout rate: 0.0, hidden size: 512, \n        hidden layer: 1, pretrained: 0\n        ", "\n        initial learning rate: 0.001, weight_decay: 3e-05\n        use lr schedular: False, total epochs: 30\n        ", "\n        step size: 10, gamma: 0.5\n        ", "Begin training, total epochs: 30", {"lr_message": "learning rate of epoch 1: 0.001", "epoch": 1, "train_message": "[ Epoch 1, Train ] | Loss:1.57979 Time:1.413458", "val_message": "[ Epoch 1, Val ] | Loss:1.58165 Time:0.067190", "epoch_train_loss": 1.5797898484699762, "epoch_val_loss": 1.581646548377143, "save_message": "save model with val loss 1.582"}, {"lr_message": "learning rate of epoch 2: 0.001", "epoch": 2, "train_message": "[ Epoch 2, Train ] | Loss:1.57010 Time:1.610645", "val_message": "[ Epoch 2, Val ] | Loss:1.57082 Time:0.060462", "epoch_train_loss": 1.5701030777461493, "epoch_val_loss": 1.570816953976949, "save_message": "save model with val loss 1.571"}, {"lr_message": "learning rate of epoch 3: 0.001", "epoch": 3, "train_message": "[ Epoch 3, Train ] | Loss:1.52801 Time:1.421185", "val_message": "[ Epoch 3, Val ] | Loss:1.56252 Time:0.067315", "epoch_train_loss": 1.5280092652164288, "epoch_val_loss": 1.5625198814604018, "save_message": "save model with val loss 1.563"}, {"lr_message": "learning rate of epoch 4: 0.001", "epoch": 4, "train_message": "[ Epoch 4, Train ] | Loss:1.46060 Time:1.588768", "val_message": "[ Epoch 4, Val ] | Loss:1.55037 Time:0.046469", "epoch_train_loss": 1.4606019916819102, "epoch_val_loss": 1.550370044178433, "save_message": "save model with val loss 1.550"}, {"lr_message": "learning rate of epoch 5: 0.001", "epoch": 5, "train_message": "[ Epoch 5, Train ] | Loss:1.42121 Time:1.394940", "val_message": "[ Epoch 5, Val ] | Loss:1.55810 Time:0.063554", "epoch_train_loss": 1.421209497238273, "epoch_val_loss": 1.5580990182028875}, {"lr_message": "learning rate of epoch 6: 0.001", "epoch": 6, "train_message": "[ Epoch 6, Train ] | Loss:1.39855 Time:1.448185", "val_message": "[ Epoch 6, Val ] | Loss:1.57641 Time:0.034777", "epoch_train_loss": 1.3985501421031667, "epoch_val_loss": 1.5764137241575453}, {"lr_message": "learning rate of epoch 7: 0.001", "epoch": 7, "train_message": "[ Epoch 7, Train ] | Loss:1.48834 Time:1.777520", "val_message": "[ Epoch 7, Val ] | Loss:1.55410 Time:0.083077", "epoch_train_loss": 1.488344615964747, "epoch_val_loss": 1.5540992948744032}, {"lr_message": "learning rate of epoch 8: 0.001", "epoch": 8, "train_message": "[ Epoch 8, Train ] | Loss:1.47248 Time:1.508794", "val_message": "[ Epoch 8, Val ] | Loss:1.56437 Time:0.087811", "epoch_train_loss": 1.4724822542560634, "epoch_val_loss": 1.5643723275926378}, {"lr_message": "learning rate of epoch 9: 0.001", "epoch": 9, "train_message": "[ Epoch 9, Train ] | Loss:1.40348 Time:1.478278", "val_message": "[ Epoch 9, Val ] | Loss:1.56659 Time:0.038499", "epoch_train_loss": 1.403482700461772, "epoch_val_loss": 1.5665892495049372}, {"lr_message": "learning rate of epoch 10: 0.001", "epoch": 10, "train_message": "[ Epoch 10, Train ] | Loss:1.47478 Time:1.498215", "val_message": "[ Epoch 10, Val ] | Loss:1.62062 Time:0.060591", "epoch_train_loss": 1.4747756203608726, "epoch_val_loss": 1.6206216944588556}, {"lr_message": "learning rate of epoch 11: 0.001", "epoch": 11, "train_message": "[ Epoch 11, Train ] | Loss:1.47825 Time:1.489417", "val_message": "[ Epoch 11, Val ] | Loss:1.58458 Time:0.056859", "epoch_train_loss": 1.4782524304603464, "epoch_val_loss": 1.584581904941135}, {"lr_message": "learning rate of epoch 12: 0.001", "epoch": 12, "train_message": "[ Epoch 12, Train ] | Loss:1.46871 Time:1.474360", "val_message": "[ Epoch 12, Val ] | Loss:1.57473 Time:0.054893", "epoch_train_loss": 1.4687063142434875, "epoch_val_loss": 1.5747328599294026}, {"lr_message": "learning rate of epoch 13: 0.001", "epoch": 13, "train_message": "[ Epoch 13, Train ] | Loss:1.45588 Time:1.463816", "val_message": "[ Epoch 13, Val ] | Loss:1.56130 Time:0.041194", "epoch_train_loss": 1.4558826756121508, "epoch_val_loss": 1.5612959067026775}, {"lr_message": "learning rate of epoch 14: 0.001", "epoch": 14, "train_message": "[ Epoch 14, Train ] | Loss:1.38657 Time:1.584629", "val_message": "[ Epoch 14, Val ] | Loss:1.55848 Time:0.066406", "epoch_train_loss": 1.3865711617825636, "epoch_val_loss": 1.5584770043690999}, {"lr_message": "learning rate of epoch 15: 0.001", "epoch": 15, "train_message": "[ Epoch 15, Train ] | Loss:1.37392 Time:1.452757", "val_message": "[ Epoch 15, Val ] | Loss:1.57585 Time:0.034755", "epoch_train_loss": 1.3739241023561848, "epoch_val_loss": 1.5758522351582844}, {"lr_message": "learning rate of epoch 16: 0.001", "epoch": 16, "train_message": "[ Epoch 16, Train ] | Loss:1.40109 Time:1.637532", "val_message": "[ Epoch 16, Val ] | Loss:1.54209 Time:0.049328", "epoch_train_loss": 1.4010899120302343, "epoch_val_loss": 1.5420860317018297, "save_message": "save model with val loss 1.542"}, {"lr_message": "learning rate of epoch 17: 0.001", "epoch": 17, "train_message": "[ Epoch 17, Train ] | Loss:1.36424 Time:1.653645", "val_message": "[ Epoch 17, Val ] | Loss:1.57909 Time:0.051564", "epoch_train_loss": 1.3642427067258465, "epoch_val_loss": 1.579092091984219}, {"lr_message": "learning rate of epoch 18: 0.001", "epoch": 18, "train_message": "[ Epoch 18, Train ] | Loss:1.34823 Time:1.402349", "val_message": "[ Epoch 18, Val ] | Loss:1.57009 Time:0.051892", "epoch_train_loss": 1.3482324080680734, "epoch_val_loss": 1.570092452896966}, {"lr_message": "learning rate of epoch 19: 0.001", "epoch": 19, "train_message": "[ Epoch 19, Train ] | Loss:1.32647 Time:1.548363", "val_message": "[ Epoch 19, Val ] | Loss:1.57555 Time:0.060966", "epoch_train_loss": 1.3264686509744446, "epoch_val_loss": 1.5755488342709012}, {"lr_message": "learning rate of epoch 20: 0.001", "epoch": 20, "train_message": "[ Epoch 20, Train ] | Loss:1.33454 Time:1.452458", "val_message": "[ Epoch 20, Val ] | Loss:1.57781 Time:0.035115", "epoch_train_loss": 1.3345370826436513, "epoch_val_loss": 1.5778090291553073}, {"lr_message": "learning rate of epoch 21: 0.001", "epoch": 21, "train_message": "[ Epoch 21, Train ] | Loss:1.32449 Time:1.617532", "val_message": "[ Epoch 21, Val ] | Loss:1.58317 Time:0.065392", "epoch_train_loss": 1.3244857183143275, "epoch_val_loss": 1.583174639277988}, {"lr_message": "learning rate of epoch 22: 0.001", "epoch": 22, "train_message": "[ Epoch 22, Train ] | Loss:1.30653 Time:1.426048", "val_message": "[ Epoch 22, Val ] | Loss:1.58660 Time:0.080855", "epoch_train_loss": 1.3065311090270084, "epoch_val_loss": 1.586599005593194}, {"lr_message": "learning rate of epoch 23: 0.001", "epoch": 23, "train_message": "[ Epoch 23, Train ] | Loss:1.30828 Time:1.383173", "val_message": "[ Epoch 23, Val ] | Loss:1.57272 Time:0.036448", "epoch_train_loss": 1.3082817348081675, "epoch_val_loss": 1.572715957959493}, {"lr_message": "learning rate of epoch 24: 0.001", "epoch": 24, "train_message": "[ Epoch 24, Train ] | Loss:1.30294 Time:1.414191", "val_message": "[ Epoch 24, Val ] | Loss:1.57010 Time:0.071517", "epoch_train_loss": 1.3029424058857249, "epoch_val_loss": 1.5701000425550673}, {"lr_message": "learning rate of epoch 25: 0.001", "epoch": 25, "train_message": "[ Epoch 25, Train ] | Loss:1.27776 Time:1.474921", "val_message": "[ Epoch 25, Val ] | Loss:1.56803 Time:0.038425", "epoch_train_loss": 1.277763608676284, "epoch_val_loss": 1.5680325428644817}, {"lr_message": "learning rate of epoch 26: 0.001", "epoch": 26, "train_message": "[ Epoch 26, Train ] | Loss:1.27618 Time:1.499434", "val_message": "[ Epoch 26, Val ] | Loss:1.59326 Time:0.098421", "epoch_train_loss": 1.2761765273649301, "epoch_val_loss": 1.5932626724243164}, {"lr_message": "learning rate of epoch 27: 0.001", "epoch": 27, "train_message": "[ Epoch 27, Train ] | Loss:1.26776 Time:1.469327", "val_message": "[ Epoch 27, Val ] | Loss:1.60882 Time:0.039349", "epoch_train_loss": 1.2677560119486566, "epoch_val_loss": 1.6088247299194336}, {"lr_message": "learning rate of epoch 28: 0.001", "epoch": 28, "train_message": "[ Epoch 28, Train ] | Loss:1.25376 Time:1.675207", "val_message": "[ Epoch 28, Val ] | Loss:1.57829 Time:0.056486", "epoch_train_loss": 1.2537636312086191, "epoch_val_loss": 1.5782899326748319}, {"lr_message": "learning rate of epoch 29: 0.001", "epoch": 29, "train_message": "[ Epoch 29, Train ] | Loss:1.23465 Time:1.503240", "val_message": "[ Epoch 29, Val ] | Loss:1.59822 Time:0.049359", "epoch_train_loss": 1.234654732604525, "epoch_val_loss": 1.5982150236765544}, {"lr_message": "learning rate of epoch 30: 0.001", "epoch": 30, "train_message": "[ Epoch 30, Train ] | Loss:1.22679 Time:1.615909", "val_message": "[ Epoch 30, Val ] | Loss:1.59107 Time:0.066154", "epoch_train_loss": 1.226786035210339, "epoch_val_loss": 1.5910739766226873}, "Test loss: 1.5413745707935758"]